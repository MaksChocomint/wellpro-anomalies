# test_segmented_analysis.py
import asyncio
import numpy as np
import pandas as pd
from typing import List, Dict, Tuple
import json
from datetime import datetime
import os

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–µ—Ç–æ–¥—ã –∏–∑ –≤–∞—à–µ–≥–æ —Ñ–∞–π–ª–∞
try:
    from methods import z_score, lof, fft, ammad
except ImportError:
    print("–û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ç–æ–¥—ã –∏–∑ methods.py")
    print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª methods.py –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ç–æ–π –∂–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏")
    exit(1)

def load_test_data(filename: str = "default.TXT") -> pd.DataFrame:
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö."""
    try:
        print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {filename}...")
        
        with open(filename, 'r', encoding='utf-8') as file:
            lines = file.readlines()
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        header_line = lines[2].strip()
        data_lines = lines[3:]
        
        df = pd.read_csv(
            pd.io.common.StringIO('\n'.join([header_line] + data_lines)),
            sep='\t',
            header=0,
            decimal=',',
            dtype=float
        )
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–ª–æ–Ω–æ–∫
        df.columns = df.columns.str.lower().str.strip()
        
        print(f"–£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π")
        print(f"–ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
        
        return df
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
        return None

def find_working_segments(data: np.ndarray) -> List[Dict]:
    """–ù–∞—Ö–æ–∂–¥–µ–Ω–∏–µ —Ä–∞–±–æ—á–∏—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ (–Ω–µ–Ω—É–ª–µ–≤—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π)."""
    segments = []
    current_segment = []
    start_idx = 0
    in_segment = False
    
    for i, value in enumerate(data):
        if value != 0:
            if not in_segment:
                in_segment = True
                start_idx = i
            current_segment.append(value)
        else:
            if in_segment:
                in_segment = False
                segments.append({
                    'start_idx': start_idx,
                    'end_idx': i - 1,
                    'values': current_segment.copy(),
                    'length': len(current_segment)
                })
                current_segment = []
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–µ–≥–º–µ–Ω—Ç
    if in_segment:
        segments.append({
            'start_idx': start_idx,
            'end_idx': len(data) - 1,
            'values': current_segment.copy(),
            'length': len(current_segment)
        })
    
    return segments

def is_normal_start_value(value: float, param_name: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞, –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ –ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–∏ –Ω–∞—á–∞–ª–µ —Ä–∞–±–æ—Ç—ã."""
    # –î–∏–∞–ø–∞–∑–æ–Ω—ã –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –ø—Ä–∏ –Ω–∞—á–∞–ª–µ —Ä–∞–±–æ—Ç—ã
    normal_ranges = {
        '—Å–∫–æ—Ä–æ—Å—Ç—å_–±—É—Ä–µ–Ω–∏—è': (0.1, 10.0),
        '–º–æ–º–µ–Ω—Ç_—Ä–æ—Ç–æ—Ä–∞': (1.0, 5.0),
        '–æ–±–æ—Ä–æ—Ç—ã_—Ä–æ—Ç–æ—Ä–∞': (10.0, 30.0),
        '–¥–∞–≤–ª–µ–Ω–∏–µ_–Ω–∞_–≤—Ö–æ–¥–µ': (50.0, 150.0),
        '—Ä–∞—Å—Ö–æ–¥_–Ω–∞_–≤—Ö–æ–¥–µ': (5.0, 12.0),
        '—Å–∫–æ—Ä–æ—Å—Ç—å_—Å–ø–æ': (0.01, 0.5),
        '–Ω–∞–≥—Ä—É–∑–∫–∞': (1.0, 4.0),
        '–¥–º–∫': (5.0, 20.0),
    }
    
    if param_name in normal_ranges:
        min_val, max_val = normal_ranges[param_name]
        return min_val <= value <= max_val
    
    return True  # –î–ª—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –±–µ–∑ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞

def is_normal_stop_value(value: float, param_name: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞, –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ –ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–µ—Ä–µ–¥ –æ—Å—Ç–∞–Ω–æ–≤–∫–æ–π."""
    # –î–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å–ª–∏—à–∫–æ–º –ª–∏ –≤—ã—Å–æ–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–µ—Ä–µ–¥ –æ—Å—Ç–∞–Ω–æ–≤–∫–æ–π
    abnormal_stop_ranges = {
        '–¥–∞–≤–ª–µ–Ω–∏–µ_–Ω–∞_–≤—Ö–æ–¥–µ': (200, float('inf')),  # –í—ã—Å–æ–∫–æ–µ –¥–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ
        '–æ–±–æ—Ä–æ—Ç—ã_—Ä–æ—Ç–æ—Ä–∞': (30, float('inf')),      # –í—ã—Å–æ–∫–∏–µ –æ–±–æ—Ä–æ—Ç—ã –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ
        '—Å–∫–æ—Ä–æ—Å—Ç—å_–±—É—Ä–µ–Ω–∏—è': (5, float('inf')),     # –í—ã—Å–æ–∫–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ
    }
    
    if param_name in abnormal_stop_ranges:
        min_val, _ = abnormal_stop_ranges[param_name]
        return value < min_val  # –ù–æ—Ä–º–∞–ª—å–Ω–æ, –µ—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞
    
    return True

async def test_method_segmented(data: pd.DataFrame, param_name: str, 
                               method_func, method_params: Dict) -> Dict:
    """
    –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–¥–∞ —Å —É—á–µ—Ç–æ–º —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Ä–∞–±–æ—Ç—ã.
    """
    data_values = data[param_name].dropna().values
    
    # 1. –ù–∞—Ö–æ–¥–∏–º —Å–µ–≥–º–µ–Ω—Ç—ã
    segments = find_working_segments(data_values)
    
    # 2. –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ (–Ω–∞—á–∞–ª–æ/–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–∞–±–æ—Ç—ã)
    transition_anomalies = 0
    transition_details = []
    
    for i in range(len(data_values) - 1):
        if data_values[i] == 0 and data_values[i+1] != 0:
            # –ù–∞—á–∞–ª–æ —Ä–∞–±–æ—Ç—ã - –ø—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ –ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ
            if not is_normal_start_value(data_values[i+1], param_name):
                transition_anomalies += 1
                transition_details.append({
                    'type': 'start',
                    'index': i+1,
                    'value': float(data_values[i+1]),
                    'previous': 0.0
                })
        elif data_values[i] != 0 and data_values[i+1] == 0:
            # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–∞–±–æ—Ç—ã - –ø—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è –ª–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–∞
            if not is_normal_stop_value(data_values[i], param_name):
                transition_anomalies += 1
                transition_details.append({
                    'type': 'stop',
                    'index': i,
                    'value': float(data_values[i]),
                    'next': 0.0
                })
    
    # 3. –ê–Ω–∞–ª–∏–∑ –≤–Ω—É—Ç—Ä–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
    segment_anomalies = []
    total_segment_anomalies = 0
    
    for seg_idx, segment in enumerate(segments):
        if len(segment['values']) >= method_params.get('min_segment_length', 10):
            segment_data = segment['values']
            
            # –ê–Ω–∞–ª–∏–∑ –º–µ—Ç–æ–¥–æ–º –≤–Ω—É—Ç—Ä–∏ —Å–µ–≥–º–µ–Ω—Ç–∞
            anomalies_in_segment = 0
            anomaly_indices = []
            window_size = method_params['window_size']
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —à–∞–≥ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞
            step = max(1, len(segment_data) // 100)
            
            for i in range(window_size, len(segment_data), step):
                window = segment_data[i-window_size:i]
                current = segment_data[i]
                
                # –î–ª—è AMMAD –ø–µ—Ä–µ–¥–∞–µ–º –∏–º—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞
                if method_func.__name__ == 'ammad':
                    is_anomaly = await method_func(
                        window + [current],
                        window_size=window_size,
                        score_threshold=method_params['threshold'],
                        param_name=param_name
                    )
                else:
                    is_anomaly = await method_func(
                        window + [current],
                        window_size=window_size,
                        score_threshold=method_params['threshold']
                    )
                
                if is_anomaly:
                    anomalies_in_segment += 1
                    anomaly_indices.append(segment['start_idx'] + i)
            
            if anomalies_in_segment > 0:
                segment_anomalies.append({
                    'segment_id': seg_idx,
                    'start': int(segment['start_idx']),
                    'end': int(segment['end_idx']),
                    'length': len(segment_data),
                    'anomalies': anomalies_in_segment,
                    'percentage': anomalies_in_segment / (len(segment_data) // step) * 100 if step > 1 else anomalies_in_segment / len(segment_data) * 100,
                    'anomaly_indices': anomaly_indices[:10]  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–≤—ã–µ 10 –∏–Ω–¥–µ–∫—Å–æ–≤
                })
                
                total_segment_anomalies += anomalies_in_segment
    
    # 4. –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    total_analyzed_points = sum(len(s['values']) for s in segments)
    
    return {
        'param_name': param_name,
        'total_points': len(data_values),
        'segments_count': len(segments),
        'transition_anomalies': transition_anomalies,
        'transition_details': transition_details,
        'segment_anomalies_count': total_segment_anomalies,
        'segment_anomalies_details': segment_anomalies,
        'total_anomalies': transition_anomalies + total_segment_anomalies,
        'anomaly_percentage': (transition_anomalies + total_segment_anomalies) / len(data_values) * 100 if len(data_values) > 0 else 0
    }

async def analyze_parameter_segmented(df: pd.DataFrame, param_name: str, 
                                     method_name: str, method_params: Dict) -> Dict:
    """–ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –æ–¥–Ω–∏–º –º–µ—Ç–æ–¥–æ–º."""
    print(f"  –ê–Ω–∞–ª–∏–∑ {method_name:8}... ", end="")
    
    # –í—ã–±–∏—Ä–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –º–µ—Ç–æ–¥–∞
    method_func = {
        'z_score': z_score,
        'lof': lof,
        'fft': fft,
        'ammad': ammad
    }.get(method_name)
    
    if method_func is None:
        print(f"–û—à–∏–±–∫–∞: –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –º–µ—Ç–æ–¥ {method_name}")
        return None
    
    try:
        results = await test_method_segmented(df, param_name, method_func, method_params)
        print(f"–≥–æ—Ç–æ–≤–æ ({results['anomaly_percentage']:.2f}% –∞–Ω–æ–º–∞–ª–∏–π)")
        return results
    except Exception as e:
        print(f"–æ—à–∏–±–∫–∞: {e}")
        return None

async def run_comprehensive_segmented_analysis(df: pd.DataFrame):
    """–ó–∞–ø—É—Å–∫ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –≤—Å–µ—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤."""
    
    print("="*80)
    print("üìä –°–ï–ì–ú–ï–ù–¢–ù–´–ô –ê–ù–ê–õ–ò–ó –ê–ù–û–ú–ê–õ–ò–ô - –ü–û–õ–ù–´–ô –¢–ï–°–¢")
    print("="*80)
    
    parameters = [
        "–≥–ª—É–±–∏–Ω–∞", "—Å–∫–æ—Ä–æ—Å—Ç—å_–±—É—Ä–µ–Ω–∏—è", "–≤–µ—Å_–Ω–∞_–∫—Ä—é–∫–µ", "–º–æ–º–µ–Ω—Ç_—Ä–æ—Ç–æ—Ä–∞",
        "–æ–±–æ—Ä–æ—Ç—ã_—Ä–æ—Ç–æ—Ä–∞", "–¥–∞–≤–ª–µ–Ω–∏–µ_–Ω–∞_–≤—Ö–æ–¥–µ", "—Ä–∞—Å—Ö–æ–¥_–Ω–∞_–≤—Ö–æ–¥–µ",
        "—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞_–Ω–∞_–≤—ã—Ö–æ–¥–µ", "—É—Ä–æ–≤–µ–Ω—å_–≤_–µ–º–∫–æ—Å—Ç–∏", "—Å–∫–æ—Ä–æ—Å—Ç—å_—Å–ø–æ",
        "–Ω–∞–≥—Ä—É–∑–∫–∞", "–¥–º–∫"
    ]
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–µ—Ç–æ–¥–æ–≤ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    method_configs = {
        'z_score': {
            '—Ç–∏–ø_A': {'window_size': 40, 'threshold': 3.5, 'min_segment_length': 20},
            '—Ç–∏–ø_B': {'window_size': 20, 'threshold': 2.5, 'min_segment_length': 5},
            '—Ç–∏–ø_C': {'window_size': 30, 'threshold': 3.0, 'min_segment_length': 10}
        },
        'lof': {
            '—Ç–∏–ø_A': {'window_size': 60, 'threshold': 15.0, 'min_segment_length': 20},
            '—Ç–∏–ø_B': {'window_size': 40, 'threshold': 10.0, 'min_segment_length': 5},
            '—Ç–∏–ø_C': {'window_size': 50, 'threshold': 12.0, 'min_segment_length': 10}
        },
        'fft': {
            '—Ç–∏–ø_A': {'window_size': 64, 'threshold': 0.15, 'min_segment_length': 20},
            '—Ç–∏–ø_B': {'window_size': 64, 'threshold': 0.10, 'min_segment_length': 5},
            '—Ç–∏–ø_C': {'window_size': 64, 'threshold': 0.12, 'min_segment_length': 10}
        },
        'ammad': {
            '—Ç–∏–ø_A': {'window_size': 40, 'threshold': 0.95, 'min_segment_length': 20},
            '—Ç–∏–ø_B': {'window_size': 30, 'threshold': 0.80, 'min_segment_length': 5},
            '—Ç–∏–ø_C': {'window_size': 35, 'threshold': 0.85, 'min_segment_length': 10}
        }
    }
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∫–∞–∂–¥–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞
    param_types = {}
    for param in parameters:
        if param in ["–≥–ª—É–±–∏–Ω–∞", "–≤–µ—Å_–Ω–∞_–∫—Ä—é–∫–µ", "—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞_–Ω–∞_–≤—ã—Ö–æ–¥–µ", "—É—Ä–æ–≤–µ–Ω—å_–≤_–µ–º–∫–æ—Å—Ç–∏"]:
            param_types[param] = '—Ç–∏–ø_A'  # –ü–æ—Å—Ç–æ—è–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        elif param in ["—Å–∫–æ—Ä–æ—Å—Ç—å_—Å–ø–æ", "—Å–∫–æ—Ä–æ—Å—Ç—å_–±—É—Ä–µ–Ω–∏—è", "–¥–º–∫", "–Ω–∞–≥—Ä—É–∑–∫–∞", 
                      "–æ–±–æ—Ä–æ—Ç—ã_—Ä–æ—Ç–æ—Ä–∞", "–º–æ–º–µ–Ω—Ç_—Ä–æ—Ç–æ—Ä–∞"]:
            param_types[param] = '—Ç–∏–ø_B'  # –ß–∞—Å—Ç–æ –Ω—É–ª–µ–≤—ã–µ
        else:
            param_types[param] = '—Ç–∏–ø_C'  # –†–µ–¥–∫–æ –Ω—É–ª–µ–≤—ã–µ
    
    all_results = {}
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_dir = f"segmented_results_{timestamp}"
    os.makedirs(results_dir, exist_ok=True)
    
    for param in parameters:
        if param not in df.columns:
            print(f"–ü–∞—Ä–∞–º–µ—Ç—Ä '{param}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
            continue
        
        print(f"\nüîç –ü–∞—Ä–∞–º–µ—Ç—Ä: {param} ({param_types[param]})")
        
        param_results = {}
        
        # –ê–Ω–∞–ª–∏–∑ –∫–∞–∂–¥—ã–º –º–µ—Ç–æ–¥–æ–º
        for method_name in ['z_score', 'lof', 'fft', 'ammad']:
            method_params = method_configs[method_name][param_types[param]]
            results = await analyze_parameter_segmented(df, param, method_name, method_params)
            
            if results:
                param_results[method_name] = results
        
        all_results[param] = param_results
        
        # –ö—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—É
        if param_results:
            print(f"  üìä –°–≤–æ–¥–∫–∞ –ø–æ –º–µ—Ç–æ–¥–∞–º:")
            for method_name, results in param_results.items():
                print(f"    {method_name:8}: {results['total_anomalies']:4} –∞–Ω–æ–º–∞–ª–∏–π "
                      f"({results['anomaly_percentage']:5.2f}%) | "
                      f"—Å–µ–≥–º–µ–Ω—Ç–æ–≤: {results['segments_count']}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ {results_dir}/")
    
    # 1. –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON
    with open(f"{results_dir}/segmented_analysis_results.json", 'w', encoding='utf-8') as f:
        json.dump(all_results, f, ensure_ascii=False, indent=2, default=str)
    
    # 2. –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –≤ CSV
    summary_data = []
    for param, methods in all_results.items():
        for method_name, results in methods.items():
            summary_data.append({
                '–ü–∞—Ä–∞–º–µ—Ç—Ä': param,
                '–ú–µ—Ç–æ–¥': method_name,
                '–¢–∏–ø': param_types.get(param, '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'),
                '–í—Å–µ–≥–æ —Ç–æ—á–µ–∫': results['total_points'],
                '–°–µ–≥–º–µ–Ω—Ç–æ–≤': results['segments_count'],
                '–ê–Ω–æ–º–∞–ª–∏–π –ø–µ—Ä–µ—Ö–æ–¥–æ–≤': results['transition_anomalies'],
                '–ê–Ω–æ–º–∞–ª–∏–π –≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ö': results['segment_anomalies_count'],
                '–í—Å–µ–≥–æ –∞–Ω–æ–º–∞–ª–∏–π': results['total_anomalies'],
                '–ü—Ä–æ—Ü–µ–Ω—Ç –∞–Ω–æ–º–∞–ª–∏–π': f"{results['anomaly_percentage']:.2f}%"
            })
    
    df_summary = pd.DataFrame(summary_data)
    df_summary.to_csv(f"{results_dir}/summary.csv", index=False, encoding='utf-8')
    
    # 3. –ü–æ–¥—Ä–æ–±–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –º–µ—Ç–æ–¥–∞–º
    for method_name in ['z_score', 'lof', 'fft', 'ammad']:
        method_data = []
        for param, methods in all_results.items():
            if method_name in methods:
                results = methods[method_name]
                method_data.append({
                    '–ü–∞—Ä–∞–º–µ—Ç—Ä': param,
                    '–í—Å–µ–≥–æ —Ç–æ—á–µ–∫': results['total_points'],
                    '–°–µ–≥–º–µ–Ω—Ç–æ–≤': results['segments_count'],
                    '–ê–Ω–æ–º–∞–ª–∏–π': results['total_anomalies'],
                    '–ü—Ä–æ—Ü–µ–Ω—Ç': results['anomaly_percentage']
                })
        
        if method_data:
            df_method = pd.DataFrame(method_data)
            df_method.to_csv(f"{results_dir}/{method_name}_results.csv", index=False, encoding='utf-8')
    
    # –í—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    print("\n" + "="*80)
    print("üìà –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("="*80)
    
    for method_name in ['z_score', 'lof', 'fft', 'ammad']:
        method_totals = {
            '–ø–∞—Ä–∞–º–µ—Ç—Ä—ã': 0,
            '–∞–Ω–æ–º–∞–ª–∏–∏': 0,
            '—Ç–æ—á–∫–∏': 0,
            '–ø—Ä–æ—Ü–µ–Ω—Ç': 0.0
        }
        
        for param, methods in all_results.items():
            if method_name in methods:
                results = methods[method_name]
                method_totals['–ø–∞—Ä–∞–º–µ—Ç—Ä—ã'] += 1
                method_totals['–∞–Ω–æ–º–∞–ª–∏–∏'] += results['total_anomalies']
                method_totals['—Ç–æ—á–∫–∏'] += results['total_points']
        
        if method_totals['—Ç–æ—á–∫–∏'] > 0:
            method_totals['–ø—Ä–æ—Ü–µ–Ω—Ç'] = method_totals['–∞–Ω–æ–º–∞–ª–∏–∏'] / method_totals['—Ç–æ—á–∫–∏'] * 100
        
        print(f"\n{method_name:8}:")
        print(f"  –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {method_totals['–ø–∞—Ä–∞–º–µ—Ç—Ä—ã']}")
        print(f"  –í—Å–µ–≥–æ –∞–Ω–æ–º–∞–ª–∏–π: {method_totals['–∞–Ω–æ–º–∞–ª–∏–∏']:,}")
        print(f"  –°—Ä–µ–¥–Ω–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –∞–Ω–æ–º–∞–ª–∏–π: {method_totals['–ø—Ä–æ—Ü–µ–Ω—Ç']:.2f}%")
    
    # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø–∞–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    print("\n" + "="*80)
    print("üî¨ –ê–ù–ê–õ–ò–ó –ü–û –¢–ò–ü–ê–ú –ü–ê–†–ê–ú–ï–¢–†–û–í")
    print("="*80)
    
    for param_type in ['—Ç–∏–ø_A', '—Ç–∏–ø_B', '—Ç–∏–ø_C']:
        type_params = [p for p, t in param_types.items() if t == param_type and p in all_results]
        
        if not type_params:
            continue
        
        print(f"\n{param_type}:")
        print(f"  –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {', '.join(type_params)}")
        
        for method_name in ['z_score', 'lof', 'fft', 'ammad']:
            type_anomalies = 0
            type_points = 0
            
            for param in type_params:
                if method_name in all_results[param]:
                    results = all_results[param][method_name]
                    type_anomalies += results['total_anomalies']
                    type_points += results['total_points']
            
            if type_points > 0:
                percentage = type_anomalies / type_points * 100
                print(f"    {method_name:8}: {type_anomalies:6} –∞–Ω–æ–º–∞–ª–∏–π ({percentage:5.2f}%)")
    
    return all_results, results_dir

async def quick_test(df: pd.DataFrame):
    """–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏."""
    print("="*80)
    print("üöÄ –ë–´–°–¢–†–´–ô –¢–ï–°–¢ –°–ï–ì–ú–ï–ù–¢–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê")
    print("="*80)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    test_params = ["–≥–ª—É–±–∏–Ω–∞", "—Å–∫–æ—Ä–æ—Å—Ç—å_–±—É—Ä–µ–Ω–∏—è", "–º–æ–º–µ–Ω—Ç_—Ä–æ—Ç–æ—Ä–∞", "–¥–∞–≤–ª–µ–Ω–∏–µ_–Ω–∞_–≤—Ö–æ–¥–µ"]
    
    for param in test_params:
        if param not in df.columns:
            continue
        
        print(f"\nüîç –ü–∞—Ä–∞–º–µ—Ç—Ä: {param}")
        data_values = df[param].dropna().values
        
        # –ù–∞—Ö–æ–¥–∏–º —Å–µ–≥–º–µ–Ω—Ç—ã
        segments = find_working_segments(data_values)
        
        print(f"  –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(data_values):,}")
        print(f"  –ù–∞–π–¥–µ–Ω–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {len(segments)}")
        
        if segments:
            segment_lengths = [s['length'] for s in segments]
            print(f"  –î–ª–∏–Ω–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: min={min(segment_lengths)}, "
                  f"max={max(segment_lengths)}, avg={np.mean(segment_lengths):.1f}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Ö–æ–¥—ã
            zero_to_nonzero = 0
            nonzero_to_zero = 0
            
            for i in range(len(data_values) - 1):
                if data_values[i] == 0 and data_values[i+1] != 0:
                    zero_to_nonzero += 1
                elif data_values[i] != 0 and data_values[i+1] == 0:
                    nonzero_to_zero += 1
            
            print(f"  –ù–∞—á–∞–ª —Ä–∞–±–æ—Ç—ã: {zero_to_nonzero}")
            print(f"  –û—Å—Ç–∞–Ω–æ–≤–æ–∫: {nonzero_to_zero}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    print("="*80)
    print("üî¨ –°–ï–ì–ú–ï–ù–¢–ù–´–ô –ê–ù–ê–õ–ò–ó –ê–ù–û–ú–ê–õ–ò–ô –í –ë–£–†–û–í–´–• –î–ê–ù–ù–´–•")
    print("="*80)
    
    import argparse
    parser = argparse.ArgumentParser(description='–°–µ–≥–º–µ–Ω—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∞–Ω–æ–º–∞–ª–∏–π')
    parser.add_argument('--file', type=str, default='default.TXT', help='–§–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏')
    parser.add_argument('--quick', action='store_true', help='–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç')
    parser.add_argument('--full', action='store_true', help='–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑')
    
    args = parser.parse_args()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df = load_test_data(args.file)
    
    if df is None:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    drilling_parameters = [
        "–≥–ª—É–±–∏–Ω–∞", "—Å–∫–æ—Ä–æ—Å—Ç—å_–±—É—Ä–µ–Ω–∏—è", "–≤–µ—Å_–Ω–∞_–∫—Ä—é–∫–µ", "–º–æ–º–µ–Ω—Ç_—Ä–æ—Ç–æ—Ä–∞",
        "–æ–±–æ—Ä–æ—Ç—ã_—Ä–æ—Ç–æ—Ä–∞", "–¥–∞–≤–ª–µ–Ω–∏–µ_–Ω–∞_–≤—Ö–æ–¥–µ", "—Ä–∞—Å—Ö–æ–¥_–Ω–∞_–≤—Ö–æ–¥–µ",
        "—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞_–Ω–∞_–≤—ã—Ö–æ–¥–µ", "—É—Ä–æ–≤–µ–Ω—å_–≤_–µ–º–∫–æ—Å—Ç–∏", "—Å–∫–æ—Ä–æ—Å—Ç—å_—Å–ø–æ",
        "–Ω–∞–≥—Ä—É–∑–∫–∞", "–¥–º–∫"
    ]
    
    available_params = [p for p in drilling_parameters if p in df.columns]
    print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {len(available_params)} –∏–∑ {len(drilling_parameters)}")
    
    if not available_params:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –∫–ª—é—á–µ–≤–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞")
        return
    
    # –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞
    if args.quick:
        asyncio.run(quick_test(df))
    else:
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∑–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        print("\n" + "="*80)
        print("‚öô  –ù–ê–°–¢–†–û–ô–ö–ê –ê–ù–ê–õ–ò–ó–ê:")
        print("="*80)
        print("–¢–∏–ø—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:")
        print("  –¢–∏–ø –ê (–ø–æ—Å—Ç–æ—è–Ω–Ω—ã–µ): –≥–ª—É–±–∏–Ω–∞, –≤–µ—Å_–Ω–∞_–∫—Ä—é–∫–µ, —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞_–Ω–∞_–≤—ã—Ö–æ–¥–µ, —É—Ä–æ–≤–µ–Ω—å_–≤_–µ–º–∫–æ—Å—Ç–∏")
        print("  –¢–∏–ø –ë (—á–∞—Å—Ç–æ –Ω—É–ª–µ–≤—ã–µ): —Å–∫–æ—Ä–æ—Å—Ç—å_—Å–ø–æ, —Å–∫–æ—Ä–æ—Å—Ç—å_–±—É—Ä–µ–Ω–∏—è, –¥–º–∫, –Ω–∞–≥—Ä—É–∑–∫–∞, –æ–±–æ—Ä–æ—Ç—ã_—Ä–æ—Ç–æ—Ä–∞, –º–æ–º–µ–Ω—Ç_—Ä–æ—Ç–æ—Ä–∞")
        print("  –¢–∏–ø –í (—Ä–µ–¥–∫–æ –Ω—É–ª–µ–≤—ã–µ): –¥–∞–≤–ª–µ–Ω–∏–µ_–Ω–∞_–≤—Ö–æ–¥–µ, —Ä–∞—Å—Ö–æ–¥_–Ω–∞_–≤—Ö–æ–¥–µ")
        print("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
        input()
        
        results, results_dir = asyncio.run(run_comprehensive_segmented_analysis(df))
        
        print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–µ: {results_dir}/")
        print(f"   - segmented_analysis_results.json - –ø–æ–ª–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
        print(f"   - summary.csv - —Å–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞")
        print(f"   - *.csv - —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∫–∞–∂–¥–æ–º—É –º–µ—Ç–æ–¥—É")

if __name__ == "__main__":
    main()