"""
Anomaly detection methods for WellPro backend.
Optimized based on statistical analysis of 12 key drilling parameters.
Special configuration based on actual data statistics.
"""

import heapq
import math
from collections import deque
from typing import Dict, List, Optional, Tuple, Any
import numpy as np

# ==================== –ö–û–ù–°–¢–ê–ù–¢–´ ====================

# –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ—Ä–æ–≥–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö
Z_SCORE_THRESHOLD = 3.0
LOF_SCORE_THRESHOLD = 25.0  # –£–º–µ–Ω—å—à–µ–Ω –∏–∑-–∑–∞ –≤—ã—Å–æ–∫–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö
FFT_SCORE_THRESHOLD = 0.25  # –£–≤–µ–ª–∏—á–µ–Ω –¥–ª—è –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ —à—É–º–∞
AMMAD_SCORE_THRESHOLD = 0.85

# –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –æ–∫–æ–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫
Z_SCORE_WINDOW_SIZE = 30
LOF_WINDOW_SIZE = 60  # –£–º–µ–Ω—å—à–µ–Ω –¥–ª—è –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä–æ–≥–æ —Ä–µ–∞–≥–∏—Ä–æ–≤–∞–Ω–∏—è
FFT_WINDOW_SIZE = 64
AMMAD_WINDOW_SIZE = 40  # –£–≤–µ–ª–∏—á–µ–Ω –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏

K_LOF = 5
EPS = 1e-10

# –§–∏–∑–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ–¥–µ–ª—ã –¥–ª—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –±—É—Ä–µ–Ω–∏—è (–Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö)
SAFETY_LIMITS = {
    "–¥–∞–≤–ª–µ–Ω–∏–µ_–Ω–∞_–≤—Ö–æ–¥–µ": {
        "min": 0,           # –±–∞—Ä (–Ω–æ—Ä–º–∞–ª—å–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω)
        "max": 400,         # –±–∞—Ä (–º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–æ–ø—É—Å—Ç–∏–º–æ–µ)
        "critical": 350     # –±–∞—Ä (–∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ)
    },
    "—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞_–Ω–∞_–≤—ã—Ö–æ–¥–µ": {
        "min": 10,          # ¬∞C (–º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ä–∞–±–æ—á–∞—è)
        "max": 50,          # ¬∞C (–º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ä–∞–±–æ—á–∞—è)
        "critical": 45      # ¬∞C (–æ–ø–∞—Å–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞)
    },
    "–º–æ–º–µ–Ω—Ç_—Ä–æ—Ç–æ—Ä–∞": {
        "min": 0,           # –∫–ù–º
        "max": 20,          # –∫–ù–º (–º–∞–∫—Å–∏–º—É–º –∏–∑ –¥–∞–Ω–Ω—ã—Ö 18.93)
        "critical": 15      # –∫–ù–º (–æ–ø–∞—Å–Ω—ã–π –º–æ–º–µ–Ω—Ç)
    },
    "—Å–∫–æ—Ä–æ—Å—Ç—å_–±—É—Ä–µ–Ω–∏—è": {
        "min": 0,           # –º/—á
        "max": 25,          # –º/—á (–º–∞–∫—Å–∏–º—É–º –∏–∑ –¥–∞–Ω–Ω—ã—Ö 24.93)
        "critical": 20      # –º/—á (–æ–ø–∞—Å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å)
    },
    "–≤–µ—Å_–Ω–∞_–∫—Ä—é–∫–µ": {
        "min": 20,          # —Ç–æ–Ω–Ω (–º–∏–Ω–∏–º—É–º –∏–∑ –¥–∞–Ω–Ω—ã—Ö 20.33)
        "max": 120,         # —Ç–æ–Ω–Ω (–º–∞–∫—Å–∏–º—É–º –∏–∑ –¥–∞–Ω–Ω—ã—Ö 117.52)
        "critical": 100     # —Ç–æ–Ω–Ω (–æ–ø–∞—Å–Ω—ã–π –≤–µ—Å)
    },
    "–≥–ª—É–±–∏–Ω–∞": {
        "min": 3430,        # –º–µ—Ç—Ä–æ–≤ (–º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∏–∑ –¥–∞–Ω–Ω—ã—Ö)
        "max": 3500,        # –º–µ—Ç—Ä–æ–≤ (–º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –∏–∑ –¥–∞–Ω–Ω—ã—Ö)
        "critical": 0       # –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —É–º–µ–Ω—å—à–µ–Ω–∏—è
    },
    "–æ–±–æ—Ä–æ—Ç—ã_—Ä–æ—Ç–æ—Ä–∞": {
        "min": 0,           # –æ–±/–º–∏–Ω
        "max": 50,          # –æ–±/–º–∏–Ω (–º–∞–∫—Å–∏–º—É–º –∏–∑ –¥–∞–Ω–Ω—ã—Ö 45.90)
        "critical": 40      # –æ–±/–º–∏–Ω (–æ–ø–∞—Å–Ω—ã–µ –æ–±–æ—Ä–æ—Ç—ã)
    },
    "—É—Ä–æ–≤–µ–Ω—å_–≤_–µ–º–∫–æ—Å—Ç–∏": {
        "min": 0.5,         # —É—Å–ª.–µ–¥.
        "max": 2.0,         # —É—Å–ª.–µ–¥. (–º–∞–∫—Å–∏–º—É–º –∏–∑ –¥–∞–Ω–Ω—ã—Ö 1.96)
        "critical": 1.8     # —É—Å–ª.–µ–¥. (–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —É—Ä–æ–≤–µ–Ω—å)
    },
    "—Ä–∞—Å—Ö–æ–¥_–Ω–∞_–≤—Ö–æ–¥–µ": {
        "min": 0,           # –ª/—Å –∏–ª–∏ –º¬≥/—á
        "max": 20,          # (–º–∞–∫—Å–∏–º—É–º –∏–∑ –¥–∞–Ω–Ω—ã—Ö 16.07)
        "critical": 15      # –æ–ø–∞—Å–Ω—ã–π —Ä–∞—Å—Ö–æ–¥
    },
    "–Ω–∞–≥—Ä—É–∑–∫–∞": {
        "min": -5,          # —Ç–æ–Ω–Ω (–º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∏–∑ –¥–∞–Ω–Ω—ã—Ö -3.99)
        "max": 10,          # —Ç–æ–Ω–Ω (–º–∞–∫—Å–∏–º—É–º –∏–∑ –¥–∞–Ω–Ω—ã—Ö 9.97)
        "critical": 8       # —Ç–æ–Ω–Ω (–æ–ø–∞—Å–Ω–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞)
    },
}

# ==================== –°–£–©–ï–°–¢–í–£–Æ–©–ò–ï –ú–ï–¢–û–î–´ ====================

async def z_score(data, window_size=Z_SCORE_WINDOW_SIZE, score_threshold=Z_SCORE_THRESHOLD):
    """
    Z-score –º–µ—Ç–æ–¥ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π.
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: –æ–∫–Ω–æ=30, –ø–æ—Ä–æ–≥=3.0
    """
    if len(data) <= window_size:
        return False
    
    window = list(data)[-window_size - 1:-1]
    current_value = data[-1]
    
    mean = np.mean(window)
    std = np.std(window)
    
    if std < EPS:
        return False
    
    z_score_value = abs((current_value - mean) / std)
    return z_score_value > score_threshold


async def lof(data, window_size=LOF_WINDOW_SIZE, score_threshold=LOF_SCORE_THRESHOLD):
    """
    Local Outlier Factor (LOF) –º–µ—Ç–æ–¥.
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: –æ–∫–Ω–æ=60, –ø–æ—Ä–æ–≥=25.0
    """
    if len(data) <= window_size:
        return False

    window = list(data)[-window_size - 1:-1]
    last_value = data[-1]

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    if all(abs(v - window[0]) < EPS for v in window) and abs(last_value - window[0]) < EPS:
        return False

    def reachability_distance(point, neighbor, k_distance):
        return max(abs(point - neighbor), k_distance)

    def local_reach_density(point, arr, k=K_LOF):
        # –ù–∞—Ö–æ–¥–∏–º k –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π
        distances = [abs(x - point) for x in arr if x != point]
        if len(distances) < k:
            return 1.0
        
        distances.sort()
        k_distance = distances[k-1] if k-1 < len(distances) else distances[-1]
        
        # –í—ã—á–∏—Å–ª—è–µ–º reachability distances
        reach_dists = [reachability_distance(point, x, k_distance) for x in arr if x != point][:k]
        
        if not reach_dists:
            return 1.0
        
        mean_reach_dist = np.mean(reach_dists)
        return 1.0 / max(mean_reach_dist, EPS)

    # –í—ã—á–∏—Å–ª—è–µ–º LRD –¥–ª—è —Ç–µ–∫—É—â–µ–π —Ç–æ—á–∫–∏
    lrd_current = local_reach_density(last_value, window)
    
    # –ù–∞—Ö–æ–¥–∏–º k –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π
    distances = [(i, abs(x - last_value)) for i, x in enumerate(window)]
    distances.sort(key=lambda x: x[1])
    k_nearest_indices = [idx for idx, _ in distances[:K_LOF]]
    
    # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ LRD —Å–æ—Å–µ–¥–µ–π
    neighbor_lrds = []
    for idx in k_nearest_indices:
        neighbor_point = window[idx]
        lrd_neighbor = local_reach_density(neighbor_point, window)
        neighbor_lrds.append(lrd_neighbor)
    
    if not neighbor_lrds:
        return False
    
    avg_neighbor_lrd = np.mean(neighbor_lrds)
    
    # –í—ã—á–∏—Å–ª—è–µ–º LOF
    if lrd_current < EPS:
        return False
    
    lof_score = avg_neighbor_lrd / lrd_current
    return lof_score > score_threshold


async def fft(data, window_size=FFT_WINDOW_SIZE, score_threshold=FFT_SCORE_THRESHOLD):
    """
    FFT –º–µ—Ç–æ–¥ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π.
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: –æ–∫–Ω–æ=64, –ø–æ—Ä–æ–≥=0.25
    """
    if len(data) < window_size:
        return False
    
    window = np.array(data[-window_size:])
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–∫–Ω–æ –•–∞–Ω–Ω–∞ –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–æ–≤ –∫—Ä–∞–µ–≤
    hann_window = np.hanning(len(window))
    window_weighted = window * hann_window
    
    # –í—ã—á–∏—Å–ª—è–µ–º FFT
    fft_vals = np.fft.fft(window_weighted)
    magnitudes = np.abs(fft_vals)
    
    total_energy = np.sum(magnitudes)
    if total_energy < EPS:
        return False
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—ã—Å–æ–∫–æ—á–∞—Å—Ç–æ—Ç–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (–æ—Ç 1/4 –¥–æ 1/2 —á–∞—Å—Ç–æ—Ç—ã –ù–∞–π–∫–≤–∏—Å—Ç–∞)
    high_freq_start = max(1, len(magnitudes) // 4)
    high_freq_end = len(magnitudes) // 2
    high_freq_energy = np.sum(magnitudes[high_freq_start:high_freq_end])
    
    high_freq_ratio = high_freq_energy / total_energy
    return high_freq_ratio > score_threshold

# ==================== AMMAD –ú–ï–¢–û–î (–û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ô) ====================

class AMMADDetector:
    """
    Adaptive Multi-Method Anomaly Detection (AMMAD)
    –ì–∏–±—Ä–∏–¥–Ω—ã–π –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –±—É—Ä–µ–Ω–∏—è.
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ 12 –∫–ª—é—á–µ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.
    """
    
    def __init__(self, param_name: str):
        self.param_name = param_name
        self.signal_history: deque = deque(maxlen=300)  # –£–≤–µ–ª–∏—á–µ–Ω —Ä–∞–∑–º–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏
        self.anomaly_history: deque = deque(maxlen=100)
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫
        self.config = self._get_param_config(param_name)
        
        # –°—á–µ—Ç—á–∏–∫–∏
        self.detection_count = 0
        self.adaptive_updates = 0
        
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø–æ–ª—è
        self.last_value = None
        self.value_trend = 0.0
        self.variance_history = deque(maxlen=50)
        
        print(f"[AMMAD] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–µ—Ç–µ–∫—Ç–æ—Ä –¥–ª—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞: {param_name}")
    
    def _get_param_config(self, param_name: str) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫."""
        base_config = {
            "min_history": 40,
            "max_history": 300,
            "strict_mode": True,
            "weight_decay": 0.95,
        }
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –∏–∑ –¥–∞–Ω–Ω—ã—Ö
        param_configs = {
            # –ì–ª—É–±–∏–Ω–∞ - —Å—Ç–∞–±–∏–ª—å–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä —Å –Ω–∏–∑–∫–∏–º CV
            "–≥–ª—É–±–∏–Ω–∞": {
            "z_weight": 0.1,           # ‚¨á –£–º–µ–Ω—å—à–∏—Ç—å (–±—ã–ª–æ 0.3)
            "lof_weight": 0.1,         # ‚¨á –£–º–µ–Ω—å—à–∏—Ç—å (–±—ã–ª–æ 0.2)
            "fft_weight": 0.8,         # ‚¨Ü –£–≤–µ–ª–∏—á–∏—Ç—å –¥–ª—è —à—É–º–∞ (–±—ã–ª–æ 0.5)
            "inertia": "very_high",
            "max_change_rate": 5.0,
            "min_change_rate": 0.01,
            "allow_monotonic_increase": True,
            "require_consensus": True,
            "confidence_threshold": 0.98,  # ‚¨Ü –£–≤–µ–ª–∏—á–∏—Ç—å (–±—ã–ª–æ 0.95)
            "depth_specific": True,
            "stability_coefficient": 0.1,  # –û—á–µ–Ω—å —Å—Ç–∞–±–∏–ª—å–Ω—ã–π
        },
            
            # –°–∫–æ—Ä–æ—Å—Ç—å –±—É—Ä–µ–Ω–∏—è - –≤—ã—Å–æ–∫–∏–π CV (2.01), –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã–π
            "—Å–∫–æ—Ä–æ—Å—Ç—å_–±—É—Ä–µ–Ω–∏—è": {
                "z_weight": 0.5,          # –°—Ä–µ–¥–Ω–∏–π –≤–µ—Å Z-score
                "lof_weight": 0.4,        # –°—Ä–µ–¥–Ω–∏–π –≤–µ—Å LOF
                "fft_weight": 0.1,        # –ù–∏–∑–∫–∏–π –≤–µ—Å FFT
                "inertia": "low",         # –ù–∏–∑–∫–∞—è –∏–Ω–µ—Ä—Ü–∏–æ–Ω–Ω–æ—Å—Ç—å
                "max_change_rate": 10.0,  # –í—ã—Å–æ–∫–∞—è –¥–æ–ø—É—Å—Ç–∏–º–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è
                "noise_threshold": 0.5,   # –ü–æ—Ä–æ–≥ —à—É–º–∞
                "require_consensus": False,
                "confidence_threshold": 0.8,
                "stability_coefficient": 2.0,  # –í—ã—Å–æ–∫–∏–π CV
            },
            
            # –î–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ –≤—Ö–æ–¥–µ - —Å—Ä–µ–¥–Ω–∏–π CV (0.73)
            "–¥–∞–≤–ª–µ–Ω–∏–µ_–Ω–∞_–≤—Ö–æ–¥–µ": {
                "z_weight": 0.4,
                "lof_weight": 0.3,
                "fft_weight": 0.3,
                "inertia": "medium",
                "max_change_rate": 50.0,  # –ë—ã—Å—Ç—Ä—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–∞–≤–ª–µ–Ω–∏—è –≤–æ–∑–º–æ–∂–Ω—ã
                "pressure_spike": 30.0,   # –ü–æ—Ä–æ–≥ —Å–∫–∞—á–∫–∞ –¥–∞–≤–ª–µ–Ω–∏—è
                "require_consensus": True,
                "confidence_threshold": 0.85,
                "stability_coefficient": 0.7,
            },
            
            # –í–µ—Å –Ω–∞ –∫—Ä—é–∫–µ - —Å—Ä–µ–¥–Ω–∏–π CV (0.39)
            "–≤–µ—Å_–Ω–∞_–∫—Ä—é–∫–µ": {
                "z_weight": 0.4,
                "lof_weight": 0.4,
                "fft_weight": 0.2,
                "inertia": "high",
                "max_change_rate": 10.0,
                "stability_threshold": 5.0,
                "require_consensus": True,
                "confidence_threshold": 0.9,
                "stability_coefficient": 0.4,
            },
            
            # –ú–æ–º–µ–Ω—Ç —Ä–æ—Ç–æ—Ä–∞ - –≤—ã—Å–æ–∫–∏–π CV (1.12)
            "–º–æ–º–µ–Ω—Ç_—Ä–æ—Ç–æ—Ä–∞": {
                "z_weight": 0.6,
                "lof_weight": 0.3,
                "fft_weight": 0.1,
                "inertia": "medium",
                "max_change_rate": 5.0,
                "torque_spike": 3.0,
                "require_consensus": False,
                "confidence_threshold": 0.8,
                "stability_coefficient": 1.1,
            },
            
            # –û–±–æ—Ä–æ—Ç—ã —Ä–æ—Ç–æ—Ä–∞ - –≤—ã—Å–æ–∫–∏–π CV (1.17)
            "–æ–±–æ—Ä–æ—Ç—ã_—Ä–æ—Ç–æ—Ä–∞": {
                "z_weight": 0.5,
                "lof_weight": 0.4,
                "fft_weight": 0.1,
                "inertia": "very_low",
                "max_change_rate": 10.0,
                "rpm_spike": 5.0,
                "require_consensus": False,
                "confidence_threshold": 0.75,
                "stability_coefficient": 1.2,
            },
            
            # –£—Ä–æ–≤–µ–Ω—å –≤ –µ–º–∫–æ—Å—Ç–∏ - –æ—á–µ–Ω—å –Ω–∏–∑–∫–∏–π CV (0.085), –æ—á–µ–Ω—å —Å—Ç–∞–±–∏–ª—å–Ω—ã–π
            "—É—Ä–æ–≤–µ–Ω—å_–≤_–µ–º–∫–æ—Å—Ç–∏": {
                "z_weight": 0.7,          # –í—ã—Å–æ–∫–∏–π –≤–µ—Å Z-score
                "lof_weight": 0.2,        # –ù–∏–∑–∫–∏–π –≤–µ—Å LOF
                "fft_weight": 0.1,        # –ù–∏–∑–∫–∏–π –≤–µ—Å FFT
                "inertia": "very_high",
                "max_change_rate": 0.1,   # –û—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
                "stability_threshold": 0.05,
                "require_consensus": True,
                "confidence_threshold": 0.98,  # –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–π –ø–æ—Ä–æ–≥
                "stability_coefficient": 0.1,
            },
            
            # –î–ú–ö - –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–π CV (1.69)
            "–¥–º–∫": {
                "z_weight": 0.3,
                "lof_weight": 0.6,
                "fft_weight": 0.1,
                "inertia": "low",
                "max_change_rate": 10.0,
                "require_consensus": False,
                "confidence_threshold": 0.75,
                "stability_coefficient": 1.7,
            },
            
            # –ù–∞–≥—Ä—É–∑–∫–∞ - –≤—ã—Å–æ–∫–∏–π CV (1.26)
            "–Ω–∞–≥—Ä—É–∑–∫–∞": {
                "z_weight": 0.4,
                "lof_weight": 0.5,
                "fft_weight": 0.1,
                "inertia": "medium",
                "max_change_rate": 3.0,
                "require_consensus": False,
                "confidence_threshold": 0.8,
                "stability_coefficient": 1.3,
            },
            
            # –†–∞—Å—Ö–æ–¥ –Ω–∞ –≤—Ö–æ–¥–µ - —Å—Ä–µ–¥–Ω–∏–π CV (0.80)
            "—Ä–∞—Å—Ö–æ–¥_–Ω–∞_–≤—Ö–æ–¥–µ": {
                "z_weight": 0.4,
                "lof_weight": 0.3,
                "fft_weight": 0.3,
                "inertia": "medium",
                "max_change_rate": 5.0,
                "flow_spike": 3.0,
                "require_consensus": True,
                "confidence_threshold": 0.85,
                "stability_coefficient": 0.8,
            },
            
            # –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –Ω–∞ –≤—ã—Ö–æ–¥–µ - —Å—Ä–µ–¥–Ω–∏–π CV (0.40)
            "—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞_–Ω–∞_–≤—ã—Ö–æ–¥–µ": {
                "z_weight": 0.3,
                "lof_weight": 0.4,
                "fft_weight": 0.3,
                "inertia": "high",
                "max_change_rate": 2.0,   # –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –º–µ–Ω—è–µ—Ç—Å—è –º–µ–¥–ª–µ–Ω–Ω–æ
                "max_gradient": 0.5,
                "require_consensus": True,
                "confidence_threshold": 0.9,
                "stability_coefficient": 0.4,
            },
            
            # –°–∫–æ—Ä–æ—Å—Ç—å –°–ü–û - –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–π CV (5.41)
            "—Å–∫–æ—Ä–æ—Å—Ç—å_—Å–ø–æ": {
                "z_weight": 0.2,
                "lof_weight": 0.7,
                "fft_weight": 0.1,
                "inertia": "very_low",
                "max_change_rate": 0.5,
                "require_consensus": False,
                "confidence_threshold": 0.7,
                "stability_coefficient": 5.4,
            },
        }
        
        if param_name in param_configs:
            return {**base_config, **param_configs[param_name]}
        else:
            # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            return {
                **base_config,
                "z_weight": 0.4,
                "lof_weight": 0.4,
                "fft_weight": 0.2,
                "inertia": "medium",
                "require_consensus": True,
                "confidence_threshold": 0.85,
                "stability_coefficient": 1.0,
            }
    
    def _calculate_signal_statistics(self) -> Dict:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ —Å–∏–≥–Ω–∞–ª–∞ —Å —É—á–µ—Ç–æ–º —Å–ø–µ—Ü–∏—Ñ–∏–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞."""
        if len(self.signal_history) < self.config["min_history"]:
            return {
                "cv": 0.0, 
                "stationarity": 1.0, 
                "noise_level": 0.0, 
                "trend": 0.0,
                "mean": 0.0,
                "std": 0.0,
                "range": 0.0
            }
        
        values = np.array(list(self.signal_history))
        
        mean_val = np.mean(values)
        std_val = np.std(values)
        cv = std_val / (abs(mean_val) + EPS)
        
        # –°—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å (—Å–∫–æ–ª—å–∑—è—â–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è)
        if len(values) >= 60:
            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ 3 —Å–µ–≥–º–µ–Ω—Ç–∞
            segment_size = len(values) // 3
            variances = []
            for i in range(3):
                start_idx = i * segment_size
                end_idx = start_idx + segment_size if i < 2 else len(values)
                segment = values[start_idx:end_idx]
                if len(segment) > 10:
                    variances.append(np.var(segment))
            
            if len(variances) >= 2:
                max_var = max(variances)
                min_var = min(variances)
                stationarity = 1.0 - (max_var - min_var) / (max_var + EPS)
            else:
                stationarity = 0.8
        else:
            stationarity = 0.8
        
        # –£—Ä–æ–≤–µ–Ω—å —à—É–º–∞ (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ —Ä–∞–∑–Ω–æ—Å—Ç–µ–π)
        if len(values) >= 10:
            diffs = np.diff(values)
            noise_level = np.std(diffs) / (abs(mean_val) + EPS)
        else:
            noise_level = 0.0
        
        # –¢—Ä–µ–Ω–¥
        if len(values) >= 20:
            x = np.arange(len(values))
            slope, _ = np.polyfit(x, values, 1)
            trend = slope / (abs(mean_val) + EPS)
            self.value_trend = slope
        else:
            trend = 0.0
        
        # –î–∏–∞–ø–∞–∑–æ–Ω –∑–Ω–∞—á–µ–Ω–∏–π
        value_range = np.max(values) - np.min(values) if len(values) > 0 else 0.0
        
        return {
            "cv": cv,
            "stationarity": stationarity,
            "noise_level": noise_level,
            "trend": trend,
            "mean": mean_val,
            "std": std_val,
            "range": value_range,
            "values": values,
        }
    
    def _calculate_adaptive_weights(self, stats: Dict) -> Tuple[float, float, float]:
        """–†–∞—Å—á–µ—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –≤–µ—Å–æ–≤ –º–µ—Ç–æ–¥–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ —Å–∏–≥–Ω–∞–ª–∞."""
        z_base = self.config.get("z_weight", 0.4)
        lof_base = self.config.get("lof_weight", 0.4)
        fft_base = self.config.get("fft_weight", 0.2)
        
        # –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –≤–µ—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —Å–∏–≥–Ω–∞–ª–∞
        stability_coeff = self.config.get("stability_coefficient", 1.0)
        
        # –î–ª—è —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ (–Ω–∏–∑–∫–∏–π CV) —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Å Z-score
        if stability_coeff < 0.5:  # –û—á–µ–Ω—å —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ
            z_base *= 1.5
            lof_base *= 0.7
            fft_base *= 0.8
        elif stability_coeff < 1.0:  # –°—Ç–∞–±–∏–ª—å–Ω—ã–µ
            z_base *= 1.2
            lof_base *= 0.9
        elif stability_coeff > 2.0:  # –û—á–µ–Ω—å –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã–µ
            z_base *= 0.6
            lof_base *= 1.4
            fft_base *= 1.0
        elif stability_coeff > 1.0:  # –í–æ–ª–∞—Ç–∏–ª—å–Ω—ã–µ
            z_base *= 0.8
            lof_base *= 1.2
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–∏—Ö —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫
        if stats["stationarity"] < 0.6:  # –ù–µ—Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–π —Å–∏–≥–Ω–∞–ª
            fft_base *= 1.3
            z_base *= 0.8
        
        if stats["noise_level"] > 0.3:  # –®—É–º–Ω—ã–π —Å–∏–≥–Ω–∞–ª
            fft_base *= 1.5
            z_base *= 0.6
        
        if abs(stats["trend"]) > 0.01:  # –°–∏–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–¥
            lof_base *= 1.3
            fft_base *= 0.7
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
        z_weight = z_base
        lof_weight = lof_base
        fft_weight = fft_base
        
        total = z_weight + lof_weight + fft_weight + EPS
        z_weight /= total
        lof_weight /= total
        fft_weight /= total
        
        # –£—á–µ—Ç –∏–Ω–µ—Ä—Ü–∏–æ–Ω–Ω–æ—Å—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞
        inertia = self.config.get("inertia", "medium")
        inertia_factors = {
            "very_high": (1.4, 0.7, 0.6),
            "high": (1.2, 0.9, 0.8),
            "medium": (1.0, 1.0, 1.0),
            "low": (0.8, 1.3, 1.2),
            "very_low": (0.6, 1.5, 1.4),
        }
        
        if inertia in inertia_factors:
            z_fact, lof_fact, fft_fact = inertia_factors[inertia]
            z_weight *= z_fact
            lof_weight *= lof_fact
            fft_weight *= fft_fact
            
            total = z_weight + lof_weight + fft_weight + EPS
            z_weight /= total
            lof_weight /= total
            fft_weight /= total
        
        return z_weight, lof_weight, fft_weight
    
    async def _calculate_individual_scores(self, value: float) -> Tuple[float, float, float]:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫ –æ—Ç –∫–∞–∂–¥–æ–≥–æ –º–µ—Ç–æ–¥–∞."""
        if len(self.signal_history) < 20:
            return 0.0, 1.0, 0.0
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—Å–µ—Ö –º–µ—Ç–æ–¥–æ–≤
        all_data = list(self.signal_history) + [value]
        
        # 1. Z-score
        if len(all_data) > Z_SCORE_WINDOW_SIZE:
            window = all_data[-Z_SCORE_WINDOW_SIZE - 1:-1]
            mean = np.mean(window)
            std = np.std(window)
            
            if std > EPS:
                z_score_val = abs((value - mean) / std)
                # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –¥–ª—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å —Ç—Ä–µ–Ω–¥–æ–º
                if abs(self.value_trend) > 0:
                    expected = mean + self.value_trend
                    if abs(value - expected) < std * 2:
                        z_score_val *= 0.7  # –£–º–µ–Ω—å—à–∞–µ–º –æ—Ü–µ–Ω–∫—É –µ—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –æ–∂–∏–¥–∞–µ–º–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ
            else:
                z_score_val = 0.0
        else:
            z_score_val = 0.0
        
        # 2. LOF (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
        if len(all_data) > LOF_WINDOW_SIZE:
            window = all_data[-LOF_WINDOW_SIZE - 1:-1]
            k = min(K_LOF, max(3, len(window) // 15))
            
            # –†–∞—Å—Å—Ç–æ—è–Ω–∏—è –¥–æ –≤—Å–µ—Ö —Ç–æ—á–µ–∫ –æ–∫–Ω–∞
            distances = [abs(x - value) for x in window]
            if distances:
                # k –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π
                nearest_dists = sorted(distances)[:k]
                if nearest_dists:
                    avg_nearest_dist = np.mean(nearest_dists)
                    local_density = 1.0 / (avg_nearest_dist + EPS)
                    
                    # –û—Ü–µ–Ω–∏–≤–∞–µ–º –ø–ª–æ—Ç–Ω–æ—Å—Ç—å —Å–æ—Å–µ–¥–µ–π
                    neighbor_densities = []
                    for i, point in enumerate(window[:20]):  # –ü—Ä–æ–≤–µ—Ä—è–µ–º 20 —Å–ª—É—á–∞–π–Ω—ã—Ö —Å–æ—Å–µ–¥–µ–π
                        point_dists = [abs(x - point) for j, x in enumerate(window) if j != i]
                        if point_dists:
                            point_nearest = sorted(point_dists)[:k]
                            neighbor_densities.append(1.0 / (np.mean(point_nearest) + EPS))
                    
                    if neighbor_densities:
                        avg_neighbor_density = np.mean(neighbor_densities)
                        lof_score = avg_neighbor_density / (local_density + EPS)
                    else:
                        lof_score = 1.0
                else:
                    lof_score = 1.0
            else:
                lof_score = 1.0
        else:
            lof_score = 1.0
        
        # 3. FFT
        if len(all_data) >= FFT_WINDOW_SIZE:
            window_fft = all_data[-FFT_WINDOW_SIZE:]
            hann_window = np.hanning(len(window_fft))
            window_weighted = np.array(window_fft) * hann_window
            
            fft_vals = np.fft.fft(window_weighted)
            magnitudes = np.abs(fft_vals)
            
            total_energy = np.sum(magnitudes)
            if total_energy > EPS:
                # –í—ã—Å–æ–∫–æ—á–∞—Å—Ç–æ—Ç–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (—à—É–º)
                high_freq_start = max(1, len(magnitudes) // 4)
                high_freq_end = len(magnitudes) // 2
                high_freq_energy = np.sum(magnitudes[high_freq_start:high_freq_end])
                fft_score = high_freq_energy / total_energy
            else:
                fft_score = 0.0
        else:
            fft_score = 0.0
        
        return z_score_val, lof_score, fft_score
    
    def _normalize_scores(self, z_score: float, lof_score: float, fft_score: float) -> Tuple[float, float, float]:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ü–µ–Ω–æ–∫ –º–µ—Ç–æ–¥–æ–≤."""
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è Z-score (—Å–∏–≥–º–æ–∏–¥–∞)
        z_norm = 1.0 / (1.0 + np.exp(-(z_score - Z_SCORE_THRESHOLD) / 1.5))
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è LOF (–ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∞—è)
        if lof_score <= 1.0:
            lof_norm = 0.0
        else:
            lof_norm = min(1.0, np.log1p(lof_score - 1.0) / np.log1p(LOF_SCORE_THRESHOLD - 1.0))
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è FFT (–ª–∏–Ω–µ–π–Ω–∞—è)
        fft_norm = min(1.0, fft_score / FFT_SCORE_THRESHOLD)
        
        return z_norm, lof_norm, fft_norm
    
    def _detect_special_cases(self, value: float, stats: Dict) -> Optional[bool]:
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤."""
        if len(self.signal_history) < 10:
            return None
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö –ø—Ä–µ–¥–µ–ª–æ–≤
        if self.param_name in SAFETY_LIMITS:
            limits = SAFETY_LIMITS[self.param_name]
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
            if "min" in limits and value < limits["min"]:
                return True
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
            if "max" in limits and value > limits["max"]:
                return True
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
            if "critical" in limits and value > limits["critical"]:
                return True
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è
        if self.last_value is not None:
            rate_of_change = abs(value - self.last_value)
            
            max_rate = self.config.get("max_change_rate")
            if max_rate is not None and rate_of_change > max_rate:
                return True
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–µ–∑–∫–∏–µ —Å–∫–∞—á–∫–∏ –¥–ª—è —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            if "–¥–∞–≤–ª–µ–Ω" in self.param_name:
                pressure_spike = self.config.get("pressure_spike", 20.0)
                if rate_of_change > pressure_spike:
                    return True
            
            if "–º–æ–º–µ–Ω—Ç" in self.param_name:
                torque_spike = self.config.get("torque_spike", 2.0)
                if rate_of_change > torque_spike:
                    return True
        
        self.last_value = value
        return None
    
    async def detect(self, value: float, strict_mode: bool = None, confidence_threshold: float = None) -> bool:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–∏.
        """
        self.signal_history.append(value)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        if strict_mode is None:
            strict_mode = self.config.get("strict_mode", True)
        
        if confidence_threshold is None:
            confidence_threshold = self.config.get("confidence_threshold", AMMAD_SCORE_THRESHOLD)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏
        if len(self.signal_history) < self.config["min_history"]:
            return False
        
        # –†–∞—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫
        stats = self._calculate_signal_statistics()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤
        special_case = self._detect_special_cases(value, stats)
        if special_case is not None:
            if special_case:
                self.anomaly_history.append(True)
                self.detection_count += 1
            return special_case
        
        # –†–∞—Å—á–µ—Ç –≤–µ—Å–æ–≤ –∏ –æ—Ü–µ–Ω–æ–∫
        z_weight, lof_weight, fft_weight = self._calculate_adaptive_weights(stats)
        z_raw, lof_raw, fft_raw = await self._calculate_individual_scores(value)
        z_norm, lof_norm, fft_norm = self._normalize_scores(z_raw, lof_raw, fft_raw)
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        final_score = (
            z_norm * z_weight +
            lof_norm * lof_weight +
            fft_norm * fft_weight
        )
        
        # –õ–æ–≥–∏–∫–∞ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è
        is_anomaly = False
        
        if self.config.get("require_consensus", True):
            # –¢—Ä–µ–±—É–µ—Ç—Å—è —Å–æ–≥–ª–∞—Å–∏–µ –º–µ—Ç–æ–¥–æ–≤
            anomaly_votes = 0
            if z_norm > 0.7:
                anomaly_votes += 1
            if lof_norm > 0.7:
                anomaly_votes += 1
            if fft_norm > 0.7:
                anomaly_votes += 1
            
            # –†–µ—à–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è –∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏
            if anomaly_votes >= 2 and final_score >= confidence_threshold:
                is_anomaly = True
            elif final_score >= confidence_threshold + 0.15:  # –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                is_anomaly = True
        else:
            # –ë–æ–ª–µ–µ –º—è–≥–∫–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            if final_score >= confidence_threshold:
                is_anomaly = True
            elif max(z_norm, lof_norm, fft_norm) > 0.9 and final_score > confidence_threshold - 0.1:
                is_anomaly = True
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        self.anomaly_history.append(is_anomaly)
        if is_anomaly:
            self.detection_count += 1
        
        return is_anomaly
    
    def get_stats(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞."""
        return {
            "param_name": self.param_name,
            "history_size": len(self.signal_history),
            "anomaly_count": self.detection_count,
            "config": self.config,
            "value_trend": self.value_trend,
        }

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –¥–µ—Ç–µ–∫—Ç–æ—Ä–æ–≤ AMMAD
_ammad_detectors: Dict[str, AMMADDetector] = {}

async def ammad(data, window_size=AMMAD_WINDOW_SIZE, score_threshold=AMMAD_SCORE_THRESHOLD, **kwargs):
    """
    AMMAD –º–µ—Ç–æ–¥ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π.
    """
    param_name = kwargs.get("param_name", "unknown")
    
    if param_name not in _ammad_detectors:
        _ammad_detectors[param_name] = AMMADDetector(param_name)
    
    detector = _ammad_detectors[param_name]
    
    if len(data) < 20:
        return False
    
    latest_value = data[-1]
    
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–æ–≥–∏–π —Ä–µ–∂–∏–º —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º –ø–æ—Ä–æ–≥–æ–º
        is_anomaly = await detector.detect(
            latest_value,
            confidence_threshold=score_threshold
        )
        return is_anomaly
    except Exception as e:
        print(f"[AMMAD] –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –¥–ª—è {param_name}: {e}")
        return False

# ==================== –°–õ–û–í–ê–†–¨ –ú–ï–¢–û–î–û–í ====================

METHODS = {
    "z_score": z_score,
    "lof": lof,
    "fft": fft,
    "ammad": ammad,
}

# ==================== –£–¢–ò–õ–ò–¢–´ ====================

def get_parameter_dimensions() -> Dict[str, str]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö.
    """
    return {
        "–≥–ª—É–±–∏–Ω–∞": "–º–µ—Ç—Ä—ã (–º)",
        "—Å–∫–æ—Ä–æ—Å—Ç—å_–±—É—Ä–µ–Ω–∏—è": "–º–µ—Ç—Ä—ã –≤ —á–∞—Å (–º/—á)",
        "–≤–µ—Å_–Ω–∞_–∫—Ä—é–∫–µ": "—Ç–æ–Ω–Ω—ã (—Ç)",
        "–º–æ–º–µ–Ω—Ç_—Ä–æ—Ç–æ—Ä–∞": "–∫–∏–ª–æ–Ω—å—é—Ç–æ–Ω-–º–µ—Ç—Ä—ã (–∫–ù¬∑–º)",
        "–æ–±–æ—Ä–æ—Ç—ã_—Ä–æ—Ç–æ—Ä–∞": "–æ–±–æ—Ä–æ—Ç—ã –≤ –º–∏–Ω—É—Ç—É (–æ–±/–º–∏–Ω)",
        "–¥–∞–≤–ª–µ–Ω–∏–µ_–Ω–∞_–≤—Ö–æ–¥–µ": "–±–∞—Ä",
        "—Ä–∞—Å—Ö–æ–¥_–Ω–∞_–≤—Ö–æ–¥–µ": "–ª–∏—Ç—Ä—ã –≤ —Å–µ–∫—É–Ω–¥—É (–ª/—Å) –∏–ª–∏ –º¬≥/—á",
        "—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞_–Ω–∞_–≤—ã—Ö–æ–¥–µ": "–≥—Ä–∞–¥—É—Å—ã –¶–µ–ª—å—Å–∏—è (¬∞C)",
        "—É—Ä–æ–≤–µ–Ω—å_–≤_–µ–º–∫–æ—Å—Ç–∏": "—É—Å–ª–æ–≤–Ω—ã–µ –µ–¥–∏–Ω–∏—Ü—ã (0-2)",
        "—Å–∫–æ—Ä–æ—Å—Ç—å_—Å–ø–æ": "–º–µ—Ç—Ä—ã –≤ —á–∞—Å (–º/—á)",
        "–Ω–∞–≥—Ä—É–∑–∫–∞": "—Ç–æ–Ω–Ω—ã (—Ç)",
        "–¥–º–∫": "—É—Å–ª–æ–≤–Ω—ã–µ –µ–¥–∏–Ω–∏—Ü—ã",
    }

def get_statistical_summary() -> Dict[str, Dict]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ —Ä–µ–∑—é–º–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.
    """
    return {
        "–≥–ª—É–±–∏–Ω–∞": {
            "—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å": "–æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è",
            "cv": 0.007,
            "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—ã—Å–æ–∫–∏–π –ø–æ—Ä–æ–≥ (0.95+)"
        },
        "—Å–∫–æ—Ä–æ—Å—Ç—å_–±—É—Ä–µ–Ω–∏—è": {
            "—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å": "–æ—á–µ–Ω—å –Ω–∏–∑–∫–∞—è",
            "cv": 2.011,
            "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ (0.7-0.8)"
        },
        "–¥–∞–≤–ª–µ–Ω–∏–µ_–Ω–∞_–≤—Ö–æ–¥–µ": {
            "—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å": "—Å—Ä–µ–¥–Ω—è—è",
            "cv": 0.734,
            "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è": "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ—Ä–æ–≥ (0.85)"
        },
        "–≤–µ—Å_–Ω–∞_–∫—Ä—é–∫–µ": {
            "—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å": "–≤—ã—Å–æ–∫–∞—è",
            "cv": 0.387,
            "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è": "–í—ã—Å–æ–∫–∏–π –ø–æ—Ä–æ–≥ (0.9)"
        },
        "–º–æ–º–µ–Ω—Ç_—Ä–æ—Ç–æ—Ä–∞": {
            "—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å": "–Ω–∏–∑–∫–∞—è",
            "cv": 1.121,
            "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è": "–ù–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ (0.8)"
        },
        "–æ–±–æ—Ä–æ—Ç—ã_—Ä–æ—Ç–æ—Ä–∞": {
            "—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å": "–Ω–∏–∑–∫–∞—è",
            "cv": 1.173,
            "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è": "–ù–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ (0.75)"
        },
        "—É—Ä–æ–≤–µ–Ω—å_–≤_–µ–º–∫–æ—Å—Ç–∏": {
            "—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å": "–æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è",
            "cv": 0.085,
            "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è": "–û—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–π –ø–æ—Ä–æ–≥ (0.98)"
        },
        "–¥–º–∫": {
            "—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å": "–æ—á–µ–Ω—å –Ω–∏–∑–∫–∞—è",
            "cv": 1.688,
            "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è": "–ù–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ (0.75)"
        },
        "–Ω–∞–≥—Ä—É–∑–∫–∞": {
            "—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å": "–Ω–∏–∑–∫–∞—è",
            "cv": 1.257,
            "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è": "–ù–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ (0.8)"
        },
        "—Ä–∞—Å—Ö–æ–¥_–Ω–∞_–≤—Ö–æ–¥–µ": {
            "—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å": "—Å—Ä–µ–¥–Ω—è—è",
            "cv": 0.801,
            "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è": "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ—Ä–æ–≥ (0.85)"
        },
        "—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞_–Ω–∞_–≤—ã—Ö–æ–¥–µ": {
            "—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å": "–≤—ã—Å–æ–∫–∞—è",
            "cv": 0.404,
            "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è": "–í—ã—Å–æ–∫–∏–π –ø–æ—Ä–æ–≥ (0.9)"
        },
        "—Å–∫–æ—Ä–æ—Å—Ç—å_—Å–ø–æ": {
            "—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å": "–æ—á–µ–Ω—å –Ω–∏–∑–∫–∞—è",
            "cv": 5.411,
            "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è": "–û—á–µ–Ω—å –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ (0.7)"
        },
    }

def get_recommended_parameters():
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫.
    """
    return {
        "z_score": {
            "window_size": Z_SCORE_WINDOW_SIZE,
            "threshold": Z_SCORE_THRESHOLD,
            "recommendation": "–õ—É—á—à–µ –≤—Å–µ–≥–æ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–≥–ª—É–±–∏–Ω–∞, —É—Ä–æ–≤–µ–Ω—å, —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞)"
        },
        "lof": {
            "window_size": LOF_WINDOW_SIZE,
            "threshold": LOF_SCORE_THRESHOLD,
            "recommendation": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –¥–ª—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (—Å–∫–æ—Ä–æ—Å—Ç—å, –º–æ–º–µ–Ω—Ç, –î–ú–ö)"
        },
        "fft": {
            "window_size": FFT_WINDOW_SIZE,
            "threshold": FFT_SCORE_THRESHOLD,
            "recommendation": "–î–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏—Ö –∞–Ω–æ–º–∞–ª–∏–π –∏ —à—É–º–∞"
        },
        "ammad": {
            "window_size": AMMAD_WINDOW_SIZE,
            "threshold": AMMAD_SCORE_THRESHOLD,
            "recommendation": "–ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–∞–∑–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"
        }
    }

def reset_ammad_detectors():
    """–°–±—Ä–æ—Å –≤—Å–µ—Ö AMMAD –¥–µ—Ç–µ–∫—Ç–æ—Ä–æ–≤."""
    global _ammad_detectors
    _ammad_detectors.clear()
    print("[AMMAD] –í—Å–µ –¥–µ—Ç–µ–∫—Ç–æ—Ä—ã —Å–±—Ä–æ—à–µ–Ω—ã")

def get_ammad_detector_stats() -> Dict[str, Dict]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –≤—Å–µ—Ö AMMAD –¥–µ—Ç–µ–∫—Ç–æ—Ä–æ–≤."""
    stats = {}
    for param_name, detector in _ammad_detectors.items():
        stats[param_name] = detector.get_stats()
    return stats

# ==================== –≠–ö–°–ü–û–†–¢ ====================

__all__ = [
    # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã
    "z_score", "lof", "fft", "ammad",
    
    # –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    "Z_SCORE_THRESHOLD", "LOF_SCORE_THRESHOLD", "FFT_SCORE_THRESHOLD", "AMMAD_SCORE_THRESHOLD",
    "Z_SCORE_WINDOW_SIZE", "LOF_WINDOW_SIZE", "FFT_WINDOW_SIZE", "AMMAD_WINDOW_SIZE",
    
    # –°–ª–æ–≤–∞—Ä—å –º–µ—Ç–æ–¥–æ–≤
    "METHODS",
    
    # –£—Ç–∏–ª–∏—Ç—ã
    "get_parameter_dimensions", "get_statistical_summary", "get_recommended_parameters",
    "reset_ammad_detectors", "get_ammad_detector_stats",
    
    # –ö–ª–∞—Å—Å—ã
    "AMMADDetector",
]

# ==================== –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ====================

if __name__ == "__main__":
    print("=" * 80)
    print("–ú–ï–¢–û–î–´ –û–ë–ù–ê–†–£–ñ–ï–ù–ò–Ø –ê–ù–û–ú–ê–õ–ò–ô –î–õ–Ø –ë–£–†–û–í–´–• –î–ê–ù–ù–´–•")
    print("–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ 12 –∫–ª—é—á–µ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
    print("=" * 80)
    
    print("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–û–ï –†–ï–ó–Æ–ú–ï –ü–ê–†–ê–ú–ï–¢–†–û–í:")
    print("=" * 80)
    
    dims = get_parameter_dimensions()
    stats = get_statistical_summary()
    
    for param, info in stats.items():
        dim = dims.get(param, "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
        print(f"\n{param:25} | –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {dim:15} | CV: {info['cv']:6.3f}")
        print(f"{' ':25} | –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å: {info['—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å']:15} | –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {info['—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è']}")
    
    print("\n" + "=" * 80)
    print("üéØ –†–ï–ö–û–ú–ï–ù–î–û–í–ê–ù–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò –î–õ–Ø –ö–ê–ñ–î–û–ì–û –ü–ê–†–ê–ú–ï–¢–†–ê:")
    print("=" * 80)
    
    print("\n1. –í—ã—Å–æ–∫–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å (CV < 0.5):")
    print("   - –ì–ª—É–±–∏–Ω–∞, –£—Ä–æ–≤–µ–Ω—å –≤ –µ–º–∫–æ—Å—Ç–∏, –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞")
    print("   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—ã—Å–æ–∫–∏–µ –ø–æ—Ä–æ–≥–∏ (0.9-0.95)")
    print("   - –¢—Ä–µ–±–æ–≤–∞—Ç—å —Å–æ–≥–ª–∞—Å–∏—è –º–µ—Ç–æ–¥–æ–≤")
    
    print("\n2. –°—Ä–µ–¥–Ω—è—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å (0.5 < CV < 1.0):")
    print("   - –î–∞–≤–ª–µ–Ω–∏–µ, –†–∞—Å—Ö–æ–¥, –í–µ—Å –Ω–∞ –∫—Ä—é–∫–µ")
    print("   - –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ (0.85)")
    
    print("\n3. –ù–∏–∑–∫–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å (CV > 1.0):")
    print("   - –°–∫–æ—Ä–æ—Å—Ç—å –±—É—Ä–µ–Ω–∏—è, –ú–æ–º–µ–Ω—Ç, –û–±–æ—Ä–æ—Ç—ã, –î–ú–ö, –ù–∞–≥—Ä—É–∑–∫–∞, –°–∫–æ—Ä–æ—Å—Ç—å –°–ü–û")
    print("   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∏–∑–∫–∏–µ –ø–æ—Ä–æ–≥–∏ (0.7-0.8)")
    print("   - –ù–µ —Ç—Ä–µ–±–æ–≤–∞—Ç—å —Å–æ–≥–ª–∞—Å–∏—è –º–µ—Ç–æ–¥–æ–≤")